# awesome-llama
Awesome repositories for using LLaMA

Original Torrent: 
```
magnet:?xt=urn:btih:36945b5958b907b3ab69e963ba0de1abdf48c16c&dn=LLaMA-HFv2-4bit&tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce
```

## Inference
- C++ implementations
  - [LLaMA.cpp](https://github.com/ggerganov/llama.cpp) - Port of Facebook's LLaMA model in C/C++
  - [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp) - Locally run an Instruction-Tuned Chat-Style LLM
- WebUI
  - [Text generation webui](https://github.com/oobabooga/text-generation-webui/) - A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.

## Models
- [Koala](https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g-GGML/blob/main/koala-13B-4bit-128g.GGML.bin)
- [Vicuna](https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g)
- [Open Assistant](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_3)

## Training
- [Alpaca Lora](https://github.com/tloen/alpaca-lora) - Instruct-tune LLaMA on consumer hardware
- [Eric Lewis's misc](https://github.com/acheong08/awesome-llama/blob/main/link_groups/ericlewis.md) - Miscellaneous data and models from [Eric Lewis](https://github.com/ericlewis)
- [Other notes](https://github.com/acheong08/awesome-llama/blob/main/training/tips.md) - My own notes on training (WIP)

## Papers
- https://ai.facebook.com/blog/large-language-model-llama-meta-ai/
